{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Example 3.7 it was already shown what the Fisher information matrix for an $x_1, .. x_n$ iid sample from $N(\\mu, \\sigma^2)$ is, so no need to repeat that here.\n",
    "\n",
    "To check the quadratic approximation for the profile likelihood of $\\mu$ and $\\sigma^2$ we must plot and compare the profile likelihoods given in Example 3.10:\n",
    "\n",
    "$$\n",
    "L(\\mu) \\propto (\\sigma_{\\mu}^2)^{-n/2}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\n",
    "\\sigma_{\\mu}^2 = \\frac{1}{n} \\sum_i (x_i - \\mu)^2\n",
    "$$\n",
    "\n",
    "and:\n",
    "\n",
    "$$\n",
    "L(\\sigma^2) \\propto (\\sigma^2)^{-n/2} \\exp \\{-n \\hat{\\sigma}^2 / (2 \\sigma^2) \\}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}^2 = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2\n",
    "$$\n",
    "\n",
    "against the quadratic approximations given by:\n",
    "\n",
    "$$\n",
    "log L(\\theta_i) \\approx -\\frac{1}{2}(I^{ii})^{-1} (\\theta_i - \\hat{\\theta}_i)^2\n",
    "$$\n",
    "\n",
    "where $\\theta = (\\mu, \\sigma^2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([0.88, 1.07, 1.27, 1.54, 1.91, 2.27, 3.84, 4.50, 4.64, 9.41])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(data)\n",
    "mu_hat = np.mean(data)\n",
    "sigma_hat_sq = (1 / n) * np.sum((data - mu_hat)**2)\n",
    "np.round(mu_hat, 2), np.round(sigma_hat_sq, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = np.array([[n / sigma_hat_sq, 0],\n",
    "              [0, n / (2 * sigma_hat_sq**2)]])\n",
    "I_inv = np.linalg.inv(I)\n",
    "display(I)\n",
    "display(I_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_likelihood(\n",
    "    parameter: float, parameter_mle: float, inv_fisher_info: float) -> np.ndarray:\n",
    "    neg_log_like = approx_neg_log_likelihood(parameter, parameter_mle, inv_fisher_info)\n",
    "    like = np.exp(-neg_log_like)\n",
    "    like /= np.max(like)\n",
    "    return like\n",
    "\n",
    "def approx_neg_log_likelihood(\n",
    "    parameter: float, parameter_mle: float, inv_fisher_info: float) -> float:\n",
    "    log_like = -0.5 * (1 / inv_fisher_info) * (parameter - parameter_mle)**2\n",
    "    neg_log_like = - log_like\n",
    "    return neg_log_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.linspace(np.min(data), np.max(data), 100)\n",
    "mu_approx_like = approx_likelihood(mu, mu_hat, I_inv[0, 0])\n",
    "sigma_sq = np.linspace(-3, 3, 100)**2\n",
    "sigma_sq = sigma_sq[sigma_sq > 0.04] # prevent divide by zero in log\n",
    "sigma_sq_approx_like = approx_likelihood(sigma_sq, sigma_hat_sq, I_inv[1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_likelihood_mu(mu: np.ndarray, data: np.ndarray) -> np.ndarray:\n",
    "    like = []\n",
    "    for m in mu:\n",
    "        neg_log_like = profile_neg_log_likelihood_mu(m, data)\n",
    "        like.append(np.exp(-neg_log_like))\n",
    "    like /= np.max(like)\n",
    "    like = np.array(like)\n",
    "    return like\n",
    "\n",
    "def profile_neg_log_likelihood_mu(mu: float, data: np.ndarray) -> float:\n",
    "    n = len(data)\n",
    "    sigma_mu_sq = (1 / n) * np.sum((data - mu)**2)\n",
    "    like = sigma_mu_sq **(-n / 2)\n",
    "    neg_log_like = -np.log(like)\n",
    "    return neg_log_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_profile_like = profile_likelihood_mu(mu, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_likelihood_sigma_sq(\n",
    "    sigma_sq: np.ndarray, sigma_sq_hat: float, n: int) -> np.ndarray:\n",
    "    like = []\n",
    "    for ss in sigma_sq:\n",
    "        neg_log_like = profile_neg_log_likelihood_sigma_sq(ss, sigma_sq_hat, n)\n",
    "        like.append(np.exp(-neg_log_like))\n",
    "    like /= np.max(like)\n",
    "    like = np.array(like)\n",
    "    return like\n",
    "\n",
    "def profile_neg_log_likelihood_sigma_sq(\n",
    "    sigma_sq: float, sigma_hat_sq: float, n: int) -> float:\n",
    "    like = np.exp((-n * sigma_hat_sq) / (2 * sigma_sq)) * sigma_sq**(-n/2)\n",
    "    neg_log_like = -np.log(like)\n",
    "    return neg_log_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_sq_profile_like = profile_likelihood_sigma_sq(sigma_sq, sigma_hat_sq, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_likelihoods(parameter, profile_like, approx_like) -> None:\n",
    "    plt.plot(parameter, approx_like, label='quadratic approx')\n",
    "    plt.plot(parameter, profile_like, label='profile likelihood')\n",
    "    plt.title('Likelihood')\n",
    "    plt.xlabel(r'$\\mu$')\n",
    "    plt.ylabel('Likelihood')\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_likelihoods(mu, mu_profile_like, mu_approx_like)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quadratic approximation for the profile likelihood of $\\mu$ looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_likelihoods(sigma_sq, sigma_sq_profile_like, sigma_sq_approx_like)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quadratic approximation for the profile likelihood of $\\sigma^2$ is not so good apart from in the vicinity of the MLE estimate. The approximation is worse at lower values of $\\sigma^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are asked to check that the curvatures at the maximum correspond to the appropriate entries of the observed Fisher information matrix. To do this it is necessary to find the Hessian term at the maximum of these 4 functions. Below we can see that the values match up nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0=3.0\n",
    "mu_mle_approx = minimize(approx_neg_log_likelihood, args=(mu_hat, I_inv[0, 0]), x0=x0)\n",
    "mu_mle_profile = minimize(profile_neg_log_likelihood_mu, args=(data), x0=x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.round(mu_mle_approx.hess_inv[0][0], 2), np.round(mu_mle_profile.hess_inv[0][0], 2),\n",
    "np.round(I_inv[0, 0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0=6.0\n",
    "sigma_sq_mle_approx = minimize(approx_neg_log_likelihood,\n",
    "                               args=(sigma_hat_sq, I_inv[1, 1]), x0=x0)\n",
    "sigma_sq_mle_profile = minimize(profile_neg_log_likelihood_sigma_sq,\n",
    "                                args=(sigma_hat_sq, n), x0=x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.round(sigma_sq_mle_approx.hess_inv[0][0], 2),\n",
    " np.round(sigma_sq_mle_profile.hess_inv[0][0], 2), np.round(I_inv[1, 1], 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
